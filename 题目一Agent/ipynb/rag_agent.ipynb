{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d43141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Optional, Literal, Dict, Any\n",
    "from typing_extensions import Annotated\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# LangGraph和LangChain相关\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 千问API\n",
    "import dashscope\n",
    "from dashscope import Generation\n",
    "\n",
    "# 设置API密钥\n",
    "dashscope.api_key = os.getenv(\"DASHSCOPE_API_KEY\", \"your-api-key\")\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"Agent状态定义\"\"\"\n",
    "    messages: Annotated[List[Dict], operator.add]  # 对话历史\n",
    "    question: str  # 当前问题\n",
    "    needs_retrieval: Optional[bool] = None  # 是否需要检索\n",
    "    retrieved_docs: List[Document]  # 检索到的文档\n",
    "    context: str  # 上下文信息\n",
    "    response: str  # AI响应\n",
    "\n",
    "class QwenAgent:\n",
    "    \"\"\"千问Agent实现\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"qwen-max\", temperature: float = 0.7):\n",
    "        \"\"\"\n",
    "        初始化Agent\n",
    "        \n",
    "        Args:\n",
    "            model_name: 千问模型名称\n",
    "            temperature: 温度参数\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.vector_store = None\n",
    "        self.embeddings = None\n",
    "        self.initialize_embeddings()\n",
    "    \n",
    "    def initialize_embeddings(self):\n",
    "        \"\"\"初始化嵌入模型\"\"\"\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "        )\n",
    "    \n",
    "    def create_vector_store(self, documents: List[str]):\n",
    "        \"\"\"\n",
    "        创建向量存储\n",
    "        \n",
    "        Args:\n",
    "            documents: 文档列表\n",
    "        \"\"\"\n",
    "        # 文档分割\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50,\n",
    "            length_function=len,\n",
    "        )\n",
    "        \n",
    "        # 创建文档对象\n",
    "        docs = []\n",
    "        for i, text in enumerate(documents):\n",
    "            docs.append(Document(\n",
    "                page_content=text,\n",
    "                metadata={\"source\": f\"doc_{i}\", \"index\": i}\n",
    "            ))\n",
    "        \n",
    "        # 分割文档\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "        \n",
    "        # 创建向量存储\n",
    "        self.vector_store = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=\"./chroma_db\"\n",
    "        )\n",
    "    \n",
    "    def load_existing_vector_store(self):\n",
    "        \"\"\"加载已有的向量存储\"\"\"\n",
    "        if os.path.exists(\"./chroma_db\"):\n",
    "            self.vector_store = Chroma(\n",
    "                persist_directory=\"./chroma_db\",\n",
    "                embedding_function=self.embeddings\n",
    "            )\n",
    "    \n",
    "    def judge_retrieval_needed(self, question: str) -> bool:\n",
    "        \"\"\"\n",
    "        判断是否需要检索\n",
    "        \n",
    "        Args:\n",
    "            question: 用户问题\n",
    "            \n",
    "        Returns:\n",
    "            bool: 是否需要检索\n",
    "        \"\"\"\n",
    "        # 需要检索的关键词类型\n",
    "        retrieval_keywords = [\n",
    "            \"文档\", \"文件\", \"资料\", \"内容\", \"信息\",\n",
    "            \"查询\", \"查找\", \"搜索\", \"检索\",\n",
    "            \"根据\", \"依据\", \"参考\", \"按照\"\n",
    "        ]\n",
    "        \n",
    "        # 具体事实性问题\n",
    "        factual_keywords = [\n",
    "            \"什么\", \"谁\", \"哪里\", \"何时\", \"为什么\", \"如何\",\n",
    "            \"多少\", \"哪些\", \"是不是\", \"有没有\"\n",
    "        ]\n",
    "        \n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        # 如果有具体的事实性询问关键词，且包含检索关键词，则可能需要检索\n",
    "        has_factual = any(keyword in question for keyword in factual_keywords)\n",
    "        has_retrieval = any(keyword in question_lower for keyword in retrieval_keywords)\n",
    "        \n",
    "        # 简单规则：如果是事实性问题且涉及文档内容，则需要检索\n",
    "        if has_factual and has_retrieval:\n",
    "            return True\n",
    "        \n",
    "        # 也可以用模型判断（更准确）\n",
    "        return self._llm_judge_retrieval(question)\n",
    "    \n",
    "    def _llm_judge_retrieval(self, question: str) -> bool:\n",
    "        \"\"\"\n",
    "        使用LLM判断是否需要检索\n",
    "        \n",
    "        Args:\n",
    "            question: 用户问题\n",
    "            \n",
    "        Returns:\n",
    "            bool: 是否需要检索\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"请判断以下问题是否需要检索文档内容来回答：\n",
    "        \n",
    "        问题：{question}\n",
    "        \n",
    "        请分析：\n",
    "        1. 这个问题是否需要查找特定文档、数据或信息？\n",
    "        2. 这个问题是否能基于一般知识回答？\n",
    "        3. 这个问题是否涉及具体的、非公开的信息？\n",
    "        \n",
    "        请只回答\"需要检索\"或\"不需要检索\"。\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = Generation.call(\n",
    "                model=self.model_name,\n",
    "                prompt=prompt,\n",
    "                temperature=0.1,\n",
    "                max_tokens=10\n",
    "            )\n",
    "            \n",
    "            result = response.output.text.strip()\n",
    "            return \"需要检索\" in result\n",
    "        except:\n",
    "            # 如果API调用失败，回退到规则判断\n",
    "            return False\n",
    "    \n",
    "    def retrieve_documents(self, question: str, k: int = 3) -> List[Document]:\n",
    "        \"\"\"\n",
    "        检索相关文档\n",
    "        \n",
    "        Args:\n",
    "            question: 用户问题\n",
    "            k: 返回的文档数量\n",
    "            \n",
    "        Returns:\n",
    "            List[Document]: 相关文档列表\n",
    "        \"\"\"\n",
    "        if not self.vector_store:\n",
    "            return []\n",
    "        \n",
    "        # 相似度检索\n",
    "        docs = self.vector_store.similarity_search(question, k=k)\n",
    "        return docs\n",
    "    \n",
    "    def call_qwen(self, messages: List[Dict], context: str = \"\") -> str:\n",
    "        \"\"\"\n",
    "        调用千问API\n",
    "        \n",
    "        Args:\n",
    "            messages: 消息历史\n",
    "            context: 检索到的上下文\n",
    "            \n",
    "        Returns:\n",
    "            str: AI响应\n",
    "        \"\"\"\n",
    "        # 构建系统提示\n",
    "        system_prompt = \"\"\"你是一个智能助手，负责回答用户的问题。\n",
    "        \n",
    "        回答要求：\n",
    "        1. 如果提供了上下文信息，请基于上下文回答\n",
    "        2. 如果上下文不包含相关信息，请基于你的知识回答\n",
    "        3. 保持回答准确、简洁、有帮助\n",
    "        \"\"\"\n",
    "        \n",
    "        # 如果有上下文，添加到系统提示中\n",
    "        if context:\n",
    "            system_prompt += f\"\\n\\n上下文信息：\\n{context}\\n\\n请基于以上上下文回答问题。\"\n",
    "        \n",
    "        # 构建完整的消息列表\n",
    "        full_messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt}\n",
    "        ] + messages\n",
    "        \n",
    "        try:\n",
    "            # 调用千问API\n",
    "            response = Generation.call(\n",
    "                model=self.model_name,\n",
    "                messages=full_messages,\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "            \n",
    "            return response.output.text\n",
    "        except Exception as e:\n",
    "            print(f\"调用千问API失败: {e}\")\n",
    "            return \"抱歉，我暂时无法回答这个问题。请稍后再试。\"\n",
    "\n",
    "class RAGAgent:\n",
    "    \"\"\"RAG Agent主类\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"初始化RAG Agent\"\"\"\n",
    "        self.agent = QwenAgent()\n",
    "        self.graph = self.build_graph()\n",
    "        self.checkpointer = MemorySaver()\n",
    "        self.config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "        \n",
    "        # 加载或创建向量存储\n",
    "        self.initialize_knowledge_base()\n",
    "    \n",
    "    def initialize_knowledge_base(self):\n",
    "        \"\"\"初始化知识库\"\"\"\n",
    "        # 尝试加载已有的向量存储\n",
    "        self.agent.load_existing_vector_store()\n",
    "        \n",
    "        # 如果没有，可以在这里添加默认文档\n",
    "        if not self.agent.vector_store:\n",
    "            default_docs = [\n",
    "                \"LangGraph是一个用于构建多步、有状态AI应用的框架。\",\n",
    "                \"RAG（检索增强生成）结合了检索系统和生成模型。\",\n",
    "                \"千问Max是阿里巴巴开发的大型语言模型。\",\n",
    "                \"多轮对话需要维护对话历史和上下文信息。\"\n",
    "            ]\n",
    "            self.agent.create_vector_store(default_docs)\n",
    "            print(\"知识库已使用默认文档初始化\")\n",
    "    \n",
    "    def add_documents(self, documents: List[str]):\n",
    "        \"\"\"\n",
    "        添加文档到知识库\n",
    "        \n",
    "        Args:\n",
    "            documents: 文档列表\n",
    "        \"\"\"\n",
    "        self.agent.create_vector_store(documents)\n",
    "        print(f\"已添加 {len(documents)} 个文档到知识库\")\n",
    "    \n",
    "    def judge_retrieval_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"\n",
    "        判断是否需要检索的节点\n",
    "        \n",
    "        Args:\n",
    "            state: 当前状态\n",
    "            \n",
    "        Returns:\n",
    "            AgentState: 更新后的状态\n",
    "        \"\"\"\n",
    "        question = state[\"question\"]\n",
    "        needs_retrieval = self.agent.judge_retrieval_needed(question)\n",
    "        \n",
    "        state[\"needs_retrieval\"] = needs_retrieval\n",
    "        print(f\"问题: '{question}' - 需要检索: {needs_retrieval}\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def retrieval_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"\n",
    "        检索节点\n",
    "        \n",
    "        Args:\n",
    "            state: 当前状态\n",
    "            \n",
    "        Returns:\n",
    "            AgentState: 更新后的状态\n",
    "        \"\"\"\n",
    "        question = state[\"question\"]\n",
    "        retrieved_docs = self.agent.retrieve_documents(question)\n",
    "        \n",
    "        # 构建上下文\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "        \n",
    "        state[\"retrieved_docs\"] = retrieved_docs\n",
    "        state[\"context\"] = context\n",
    "        \n",
    "        print(f\"检索到 {len(retrieved_docs)} 个相关文档\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def generate_response_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"\n",
    "        生成响应节点\n",
    "        \n",
    "        Args:\n",
    "            state: 当前状态\n",
    "            \n",
    "        Returns:\n",
    "            AgentState: 更新后的状态\n",
    "        \"\"\"\n",
    "        # 获取对话历史\n",
    "        messages = state.get(\"messages\", [])\n",
    "        question = state[\"question\"]\n",
    "        \n",
    "        # 将用户问题添加到消息历史\n",
    "        messages.append({\"role\": \"user\", \"content\": question})\n",
    "        \n",
    "        # 获取上下文\n",
    "        context = state.get(\"context\", \"\")\n",
    "        \n",
    "        # 调用千问生成响应\n",
    "        response = self.agent.call_qwen(messages, context)\n",
    "        \n",
    "        # 将AI响应添加到消息历史\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "        state[\"response\"] = response\n",
    "        state[\"messages\"] = messages\n",
    "        \n",
    "        print(f\"生成响应完成\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def direct_response_node(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"\n",
    "        直接响应节点（无需检索）\n",
    "        \n",
    "        Args:\n",
    "            state: 当前状态\n",
    "            \n",
    "        Returns:\n",
    "            AgentState: 更新后的状态\n",
    "        \"\"\"\n",
    "        # 没有检索，直接生成响应\n",
    "        state[\"context\"] = \"\"\n",
    "        state[\"retrieved_docs\"] = []\n",
    "        \n",
    "        return self.generate_response_node(state)\n",
    "    \n",
    "    def route_based_on_retrieval(self, state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        根据是否需要检索路由到不同节点\n",
    "        \n",
    "        Args:\n",
    "            state: 当前状态\n",
    "            \n",
    "        Returns:\n",
    "            str: 下一个节点名称\n",
    "        \"\"\"\n",
    "        if state[\"needs_retrieval\"]:\n",
    "            return \"retrieval\"\n",
    "        else:\n",
    "            return \"direct_response\"\n",
    "    \n",
    "    def build_graph(self):\n",
    "        \"\"\"\n",
    "        构建工作流图\n",
    "        \n",
    "        Returns:\n",
    "            StateGraph: 构建好的图\n",
    "        \"\"\"\n",
    "        # 创建图\n",
    "        workflow = StateGraph(AgentState)\n",
    "        \n",
    "        # 添加节点\n",
    "        workflow.add_node(\"judge_retrieval\", self.judge_retrieval_node)\n",
    "        workflow.add_node(\"retrieval\", self.retrieval_node)\n",
    "        workflow.add_node(\"direct_response\", self.direct_response_node)\n",
    "        workflow.add_node(\"generate_response\", self.generate_response_node)\n",
    "        \n",
    "        # 设置入口点\n",
    "        workflow.set_entry_point(\"judge_retrieval\")\n",
    "        \n",
    "        # 添加条件边\n",
    "        workflow.add_conditional_edges(\n",
    "            \"judge_retrieval\",\n",
    "            self.route_based_on_retrieval,\n",
    "            {\n",
    "                \"retrieval\": \"retrieval\",\n",
    "                \"direct_response\": \"direct_response\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 添加普通边\n",
    "        workflow.add_edge(\"retrieval\", \"generate_response\")\n",
    "        workflow.add_edge(\"direct_response\", END)\n",
    "        workflow.add_edge(\"generate_response\", END)\n",
    "        \n",
    "        # 编译图\n",
    "        return workflow.compile()\n",
    "    \n",
    "    def process_query(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        处理用户查询\n",
    "        \n",
    "        Args:\n",
    "            question: 用户问题\n",
    "            \n",
    "        Returns:\n",
    "            Dict: 处理结果\n",
    "        \"\"\"\n",
    "        # 初始状态\n",
    "        initial_state = AgentState(\n",
    "            messages=[],\n",
    "            question=question,\n",
    "            needs_retrieval=None,\n",
    "            retrieved_docs=[],\n",
    "            context=\"\",\n",
    "            response=\"\"\n",
    "        )\n",
    "        \n",
    "        # 执行图\n",
    "        result = self.graph.invoke(\n",
    "            initial_state,\n",
    "            config=self.config\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"response\": result[\"response\"],\n",
    "            \"needs_retrieval\": result[\"needs_retrieval\"],\n",
    "            \"retrieved_docs_count\": len(result[\"retrieved_docs\"]),\n",
    "            \"context\": result[\"context\"],\n",
    "            \"messages\": result[\"messages\"]\n",
    "        }\n",
    "    \n",
    "    def chat(self):\n",
    "        \"\"\"交互式聊天\"\"\"\n",
    "        print(\"=\" * 50)\n",
    "        print(\"RAG Agent 聊天系统\")\n",
    "        print(\"支持多轮对话，输入 'quit' 或 '退出' 结束\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # 获取用户输入\n",
    "                user_input = input(\"\\n你: \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', '退出', 'exit']:\n",
    "                    print(\"再见！\")\n",
    "                    break\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                # 处理查询\n",
    "                result = self.process_query(user_input)\n",
    "                \n",
    "                # 显示响应\n",
    "                print(f\"\\n助手: {result['response']}\")\n",
    "                \n",
    "                # 显示检索信息（可选）\n",
    "                if result['needs_retrieval'] and result['retrieved_docs_count'] > 0:\n",
    "                    print(f\"[已检索 {result['retrieved_docs_count']} 个相关文档]\")\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\n对话已中断\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"错误: {e}\")\n",
    "                continue\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 创建Agent\n",
    "    rag_agent = RAGAgent()\n",
    "    \n",
    "    # 可选：添加自定义文档\n",
    "    custom_docs = input(\"是否要添加自定义文档？(y/n): \").strip().lower()\n",
    "    if custom_docs == 'y':\n",
    "        docs = []\n",
    "        print(\"请输入文档内容（输入空行结束）：\")\n",
    "        while True:\n",
    "            line = input()\n",
    "            if not line.strip():\n",
    "                break\n",
    "            docs.append(line)\n",
    "        \n",
    "        if docs:\n",
    "            rag_agent.add_documents(docs)\n",
    "    \n",
    "    # 开始聊天\n",
    "    rag_agent.chat()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
